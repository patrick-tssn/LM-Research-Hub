# Reading Materials for Transformer

## Paper
Attention is All you Need, [arxiv](https://arxiv.org/abs/1706.03762)

## Blog

Jianlin Su's blog -- Transformer升级之路

- Transformer升级之路：1、Sinusoidal位置编码追根溯源 [link](https://kexue.fm/archives/8231)
- Transformer升级之路：2、博采众长的旋转式位置编码 [link](https://kexue.fm/archives/8265)
    - Prerequisite: 让研究人员绞尽脑汁的Transformer位置编码 [link](https://kexue.fm/archives/8130)
- Transformer升级之路：3、从Performer到线性Attention [link](https://kexue.fm/archives/8338)
    - Prerequisite_1: 线性Attention的探索：Attention必须有个Softmax吗？ [link](https://kexue.fm/archives/7546)
    - Prerequisite_2: Performer：用随机投影将Attention的复杂度线性化 [link](https://kexue.fm/archives/7921)
- Transformer升级之路：4、二维位置的旋转式位置编码 [link](https://kexue.fm/archives/8397)
- Transformer升级之路：5、作为无限维的线性Attention [link](https://kexue.fm/archives/8601)
- Transformer升级之路：6、旋转位置编码的完备性分析 [link](https://kexue.fm/archives/9403)
- Transformer升级之路：7、长度外推性与局部注意力 [link](https://kexue.fm/archives/9431)
- Transformer升级之路：8、长度外推性与位置鲁棒性 [link](https://kexue.fm/archives/9444)
    - Prerequisite_1: 浅谈Transformer的初始化、参数化与标准化 [link](https://kexue.fm/archives/8620)
    - Prerequisite_2: 从熵不变性看Attention的Scale操作 [link](https://kexue.fm/archives/8823)
- Transformer升级之路：9、一种全局长度外推的新思路 [link](https://kexue.fm/archives/9603)
- Transformer升级之路：10、RoPE是一种β进制编码 [link](https://kexue.fm/archives/9675)
- Transformer升级之路：11、将β进制位置进行到底 [link](https://kexue.fm/archives/9706)
- Transformer升级之路：12、无限外推的ReRoPE？[link](https://kexue.fm/archives/9708)
- Transformer升级之路：13、逆用Leaky ReRoPE [link](https://kexue.fm/archives/9728)
- Transformer升级之路：14、当HWFA遇见ReRoPE [link](https://kexue.fm/archives/9731)
- Transformer升级之路：15、Key归一化助力长度外推 [link](https://kexue.fm/archives/9859)
- Transformer升级之路：16、“复盘”长度外推技术 [link](https://kexue.fm/archives/9948)
- Transformer升级之路：17、多模态位置编码的简单思考 [link](https://kexue.fm/archives/10040)