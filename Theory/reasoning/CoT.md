# Chain of Thought

## Papers

| Title                                                                 | Pub          | Preprint                                    | Supplementary                                               |
| --------------------------------------------------------------------- | ------------ | ------------------------------------------- | ----------------------------------------------------------- |
| Reasoning with language model is planning with world model            |              | [2305.14992](https://arxiv.org/abs/2305.14992) | [llm-reasoners](https://github.com/Ber666/llm-reasoners), UCSD |
| Decomposed Prompting: A Modular Approach for Solving Complex Tasks    | ICLR 2023    | [2210.02406](https://arxiv.org/abs/2210.02406) | AI2                                                         |
| Chain-of-Thought Prompting Elicits Reasoning in Large Language Models | Neurips 2022 | [2201.11903](https://arxiv.org/abs/2201.11903) | Google                                                      |

## Reference

- [Chain-of-ThoughtsPapers](https://github.com/Timothyxxx/Chain-of-ThoughtsPapers), A trend starts from "Chain of Thought Prompting Elicits Reasoning in Large Language Models"
- [Reasoning in Large Language Models](https://github.com/atfortes/LLM-Reasoning-Papers)
